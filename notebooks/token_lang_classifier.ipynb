{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"token_lang_classifier.ipynb","provenance":[{"file_id":"1msks93MAODNZRw4MLRsNQcP-dWeNepOA","timestamp":1652291205679},{"file_id":"1ChlQYkhAyaIpGmJ4FbVv-55sXdRFbCBi","timestamp":1652127145339}],"collapsed_sections":[],"authorship_tag":"ABX9TyPlgtf20zapq6o3H6xZCAG8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e6efde2c0f4d40e2a687e7b53ea089a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_efde669ec7e04444866837dfc615ab3e","IPY_MODEL_723ecb9d73a04fe69b26ac3e22dbecb2","IPY_MODEL_3ec04321150549f29acfcecad93d6a86"],"layout":"IPY_MODEL_14a5eccca06c495cb804aa2a8002ef5e"}},"efde669ec7e04444866837dfc615ab3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6553c428991941e9b6552abce3b61959","placeholder":"​","style":"IPY_MODEL_c8468ac63cad413a8741ca7f91356221","value":"100%"}},"723ecb9d73a04fe69b26ac3e22dbecb2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_04a6b3dc0c1d41dca4a94a338336bca1","max":90,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a73f981e6fbf4fb4b85c69df8691db72","value":90}},"3ec04321150549f29acfcecad93d6a86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1057620222848bfaa34273714b10559","placeholder":"​","style":"IPY_MODEL_7fe3e14a12424d4da4306f2977653c21","value":" 90/90 [00:50&lt;00:00,  2.43ba/s]"}},"14a5eccca06c495cb804aa2a8002ef5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6553c428991941e9b6552abce3b61959":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8468ac63cad413a8741ca7f91356221":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04a6b3dc0c1d41dca4a94a338336bca1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a73f981e6fbf4fb4b85c69df8691db72":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e1057620222848bfaa34273714b10559":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fe3e14a12424d4da4306f2977653c21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a9m2rhyvhSYx","executionInfo":{"status":"ok","timestamp":1652365451455,"user_tz":-180,"elapsed":484,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}},"outputId":"b41426e4-0566-4525-e73a-cbd2cad11115"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu May 12 14:24:10 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","!pip install seqeval"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WKROQTp2o95z","executionInfo":{"status":"ok","timestamp":1652365462970,"user_tz":-180,"elapsed":10996,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}},"outputId":"065bb911-b2ea-4d97-a108-8393dba0b4f9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.2.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.3.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n","from transformers import EvalPrediction\n","import torch\n","from google.colab import drive\n","from datasets import load_dataset\n","from transformers import AutoTokenizer\n","from datasets import ClassLabel\n","from transformers import AutoModelForSequenceClassification\n","from transformers import TrainingArguments\n","import numpy as np\n","import pandas as pd\n","from datasets import load_metric\n","from transformers import Trainer\n","from sklearn.metrics import classification_report\n","\n","drive.mount('/content/drive')\n","google_path = 'drive/MyDrive/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xqrTEgKXidnY","executionInfo":{"status":"ok","timestamp":1652365469254,"user_tz":-180,"elapsed":6295,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}},"outputId":"d7cc5aa1-be7e-4ed2-b667-a1a637114bf6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["all_langs = [\n","    'ru',\n","    'uk',\n","    'ka',\n","    'he',\n","    'en',\n","    'de',\n","    'be',\n","    'kk',\n","    'az',\n","    'hy',\n","]\n","\n","labels = ClassLabel(num_classes=10, names=all_langs)"],"metadata":{"id":"1r3iWFvH-Voe","executionInfo":{"status":"ok","timestamp":1652365469255,"user_tz":-180,"elapsed":23,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7SH6fVEcfO_S","executionInfo":{"status":"ok","timestamp":1652365469255,"user_tz":-180,"elapsed":19,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}},"outputId":"c812df60-7baa-49a4-f1a0-73b7bf7c7a0a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 89996\n","    })\n","    test: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 10000\n","    })\n","})"]},"metadata":{},"execution_count":5}],"source":["import datasets\n","\n","dataset = datasets.load_from_disk(\n","                       google_path+'dataset',\n","                       )\n","dataset"]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n","label_all_tokens = True"],"metadata":{"id":"eulg8PFj8zsz","executionInfo":{"status":"ok","timestamp":1652365477784,"user_tz":-180,"elapsed":8537,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def tokenize(examples):\n","    tokenized_inputs = tokenizer(examples[\"text\"], truncation=True, is_split_into_words=True, max_length=128)\n","\n","    labels = []\n","    for i, label in enumerate(examples[\"label\"]):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:\n","            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n","            # ignored in the loss function.\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            # We set the label for the first token of each word.\n","            elif word_idx != previous_word_idx:\n","                label_ids.append(label[word_idx])\n","            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n","            # the label_all_tokens flag.\n","            else:\n","                label_ids.append(label[word_idx] if label_all_tokens else -100)\n","            previous_word_idx = word_idx\n","\n","        labels.append(label_ids)\n","\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs\n","\n","tokenized_datasets = dataset.map(tokenize, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["e6efde2c0f4d40e2a687e7b53ea089a4","efde669ec7e04444866837dfc615ab3e","723ecb9d73a04fe69b26ac3e22dbecb2","3ec04321150549f29acfcecad93d6a86","14a5eccca06c495cb804aa2a8002ef5e","6553c428991941e9b6552abce3b61959","c8468ac63cad413a8741ca7f91356221","04a6b3dc0c1d41dca4a94a338336bca1","a73f981e6fbf4fb4b85c69df8691db72","e1057620222848bfaa34273714b10559","7fe3e14a12424d4da4306f2977653c21"]},"id":"Jo4Db_SZgWWp","executionInfo":{"status":"ok","timestamp":1652365527869,"user_tz":-180,"elapsed":50101,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}},"outputId":"24942848-5cab-4a86-8cc1-ff671bc0a1e0"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/90 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6efde2c0f4d40e2a687e7b53ea089a4"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Loading cached processed dataset at drive/MyDrive/dataset/test/cache-0602777371272ba2.arrow\n"]}]},{"cell_type":"code","source":["train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n","eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42)"],"metadata":{"id":"dqoZvVT9gWZ-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652365527869,"user_tz":-180,"elapsed":8,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}},"outputId":"de934e46-24f6-4cc5-bc72-2c8f76d8679f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["Loading cached shuffled indices for dataset at drive/MyDrive/dataset/test/cache-2ebd8a3075a31572.arrow\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForTokenClassification\n","\n","model = AutoModelForTokenClassification.from_pretrained(\n","    \"xlm-roberta-base\",\n","     num_labels=10, \n",")\n","model.config.id2label = {id: lang for id, lang in enumerate(all_langs)}\n","model.config.label2id = {lang: id for id, lang in enumerate(all_langs)}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMkWIw2zgWdH","executionInfo":{"status":"ok","timestamp":1652365533096,"user_tz":-180,"elapsed":5230,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}},"outputId":"b520833b-b0b1-433d-cf17-a498e8b8fa77"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n","- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["from transformers import DataCollatorForTokenClassification\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer)"],"metadata":{"id":"-uEakORHPT07","executionInfo":{"status":"ok","timestamp":1652365533097,"user_tz":-180,"elapsed":7,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["metric = load_metric(\"seqeval\")"],"metadata":{"id":"zmM6A57XPT3J","executionInfo":{"status":"ok","timestamp":1652365534582,"user_tz":-180,"elapsed":1490,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [all_langs[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [all_langs[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    results = metric.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": results[\"overall_precision\"],\n","        \"recall\": results[\"overall_recall\"],\n","        \"f1\": results[\"overall_f1\"],\n","        \"accuracy\": results[\"overall_accuracy\"],\n","    }"],"metadata":{"id":"EcpPqVcRPiPF","executionInfo":{"status":"ok","timestamp":1652365534582,"user_tz":-180,"elapsed":8,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["batch_size = 16\n","\n","training_args = TrainingArguments(\n","    output_dir=google_path+\"token-lang-xlm-roberta-base\",\n","    overwrite_output_dir=True,\n","    logging_strategy = \"epoch\",\n","    save_strategy = \"steps\",\n","    # evaluation_strategy = \"epoch\",\n","    evaluation_strategy = \"steps\",\n","    save_steps=2000,\n","    eval_steps=2000,\n","    save_total_limit=1,\n","    num_train_epochs=1,\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n",")"],"metadata":{"id":"PmURyF5Og0AW","executionInfo":{"status":"ok","timestamp":1652365534583,"user_tz":-180,"elapsed":7,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["train_dataset = train_dataset.remove_columns(['label'])\n","eval_dataset = eval_dataset.remove_columns(['label'])"],"metadata":{"id":"NnP_-vdgaQGY","executionInfo":{"status":"ok","timestamp":1652365534583,"user_tz":-180,"elapsed":6,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["len(train_dataset['labels'][0]),len(train_dataset['input_ids'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xu9MRDtyaoH3","executionInfo":{"status":"ok","timestamp":1652365541221,"user_tz":-180,"elapsed":6644,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}},"outputId":"d7c4c85d-c743-4acc-a718-7855dd6ef2e1"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(82, 82)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")"],"metadata":{"id":"-WQaa52Pg5LH","executionInfo":{"status":"ok","timestamp":1652365545139,"user_tz":-180,"elapsed":3923,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"5bgkZXlbg5Nk","outputId":"1e892be2-d9aa-4fde-f014-0d5070d3bb71","executionInfo":{"status":"ok","timestamp":1652370947989,"user_tz":-180,"elapsed":5253631,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set  don't have a corresponding argument in `XLMRobertaForTokenClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForTokenClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 89996\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5625\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5625' max='5625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5625/5625 1:27:32, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>2000</td>\n","      <td>No log</td>\n","      <td>0.036881</td>\n","      <td>0.894798</td>\n","      <td>0.914330</td>\n","      <td>0.904458</td>\n","      <td>0.989305</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>No log</td>\n","      <td>0.029172</td>\n","      <td>0.919623</td>\n","      <td>0.933586</td>\n","      <td>0.926552</td>\n","      <td>0.991883</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `XLMRobertaForTokenClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 10000\n","  Batch size = 16\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: en seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: be seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ka seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: kk seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: he seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: az seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: de seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: uk seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ru seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: hy seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","Saving model checkpoint to drive/MyDrive/token-lang-xlm-roberta-base/checkpoint-2000\n","Configuration saved in drive/MyDrive/token-lang-xlm-roberta-base/checkpoint-2000/config.json\n","Model weights saved in drive/MyDrive/token-lang-xlm-roberta-base/checkpoint-2000/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `XLMRobertaForTokenClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 10000\n","  Batch size = 16\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: en seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: be seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ka seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: kk seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: he seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: az seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: de seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: uk seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ru seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: hy seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","Saving model checkpoint to drive/MyDrive/token-lang-xlm-roberta-base/checkpoint-4000\n","Configuration saved in drive/MyDrive/token-lang-xlm-roberta-base/checkpoint-4000/config.json\n","Model weights saved in drive/MyDrive/token-lang-xlm-roberta-base/checkpoint-4000/pytorch_model.bin\n","Deleting older checkpoint [drive/MyDrive/token-lang-xlm-roberta-base/checkpoint-2000] due to args.save_total_limit\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=5625, training_loss=0.05178787434895833, metrics={'train_runtime': 5253.1903, 'train_samples_per_second': 17.132, 'train_steps_per_second': 1.071, 'total_flos': 5822978416659840.0, 'train_loss': 0.05178787434895833, 'epoch': 1.0})"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["trainer.save_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L31HAbS0g5QL","executionInfo":{"status":"ok","timestamp":1652180723031,"user_tz":-180,"elapsed":5417,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}},"outputId":"48703479-d523-40c9-b46a-335f078b5b74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to drive/MyDrive/ml-lang-xlm-roberta-base\n","Configuration saved in drive/MyDrive/ml-lang-xlm-roberta-base/config.json\n","Model weights saved in drive/MyDrive/ml-lang-xlm-roberta-base/pytorch_model.bin\n"]}]},{"cell_type":"code","source":["model_path = 'drive/MyDrive/ml-lang-xlm-roberta-base'\n","tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n","model = AutoModelForSequenceClassification.from_pretrained(model_path)"],"metadata":{"id":"mvmzD6w8g5Si"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.config.id2label = {id: lang for id, lang in enumerate(all_langs)}\n","model.config.label2id = {lang: id for id, lang in enumerate(all_langs)}"],"metadata":{"id":"cRIrMYrA-iEF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xtyRzDUo_LF_","executionInfo":{"status":"ok","timestamp":1652215669180,"user_tz":-180,"elapsed":282,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}},"outputId":"98130bbb-1bb8-473b-8700-b0e609536028"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XLMRobertaConfig {\n","  \"_name_or_path\": \"drive/MyDrive/ml-lang-xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"ru\",\n","    \"1\": \"uk\",\n","    \"2\": \"ka\",\n","    \"3\": \"he\",\n","    \"4\": \"en\",\n","    \"5\": \"de\",\n","    \"6\": \"be\",\n","    \"7\": \"kk\",\n","    \"8\": \"az\",\n","    \"9\": \"hy\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"az\": 8,\n","    \"be\": 6,\n","    \"de\": 5,\n","    \"en\": 4,\n","    \"he\": 3,\n","    \"hy\": 9,\n","    \"ka\": 2,\n","    \"kk\": 7,\n","    \"ru\": 0,\n","    \"uk\": 1\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"multi_label_classification\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.18.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["preds = trainer.predict(eval_dataset)\n","preds = preds.predictions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"id":"l2Fk3PfvuCp-","executionInfo":{"status":"ok","timestamp":1652216261955,"user_tz":-180,"elapsed":66606,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}},"outputId":"71043b76-a439-4576-967e-4a9e4567c562"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the test set  don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: he, text, uk, en, ka, kk, hy, be, az, de, ru. If he, text, uk, en, ka, kk, hy, be, az, de, ru are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 9906\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1240' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [620/620 02:52]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(torch.Tensor(preds))\n","probs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F1SxpCBwwnDt","executionInfo":{"status":"ok","timestamp":1652216781821,"user_tz":-180,"elapsed":523,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}},"outputId":"6f34d8f5-c759-49d7-b219-5c2911123acf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.9976, 0.0113, 0.0602,  ..., 0.0392, 0.0769, 0.9977],\n","        [0.7149, 0.0705, 0.0783,  ..., 0.0460, 0.9995, 0.0232],\n","        [0.9826, 0.0191, 0.9967,  ..., 0.0125, 0.9987, 0.0108],\n","        ...,\n","        [0.0100, 0.9966, 0.0565,  ..., 0.0212, 0.9942, 0.0138],\n","        [0.0047, 0.0048, 0.0232,  ..., 0.0070, 0.0074, 0.0080],\n","        [0.0117, 0.0125, 0.9928,  ..., 0.9895, 0.0143, 0.0074]])"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["probs[probs > 0.5] = 1\n","probs[probs <= 0.5] = 0\n","probs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ixufGRGUwnGe","executionInfo":{"status":"ok","timestamp":1652216786061,"user_tz":-180,"elapsed":298,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}},"outputId":"a4bbd11d-5a0d-45f9-8e31-1783c2b51051"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 0.,  ..., 0., 0., 1.],\n","        [1., 0., 0.,  ..., 0., 1., 0.],\n","        [1., 0., 1.,  ..., 0., 1., 0.],\n","        ...,\n","        [0., 1., 0.,  ..., 0., 1., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 1.,  ..., 1., 0., 0.]])"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["probs = probs.int().tolist()\n","pd.DataFrame(data=probs, columns=all_langs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"d430DPILwoQX","executionInfo":{"status":"ok","timestamp":1652216851053,"user_tz":-180,"elapsed":292,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}},"outputId":"9bb0d4eb-5842-4250-b33b-9d5667ba44f6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      ru  uk  ka  he  en  de  be  kk  az  hy\n","0      1   0   0   0   1   0   1   0   0   1\n","1      1   0   0   0   0   0   1   0   1   0\n","2      1   0   1   0   0   0   0   0   1   0\n","3      0   0   0   0   0   1   0   1   0   0\n","4      0   0   0   0   0   0   0   1   0   0\n","...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n","9901   0   0   0   0   1   0   0   0   0   0\n","9902   1   1   0   0   0   0   0   0   1   0\n","9903   0   1   0   0   1   0   0   0   1   0\n","9904   0   0   0   1   0   0   0   0   0   0\n","9905   0   0   1   1   0   1   0   1   0   0\n","\n","[9906 rows x 10 columns]"],"text/html":["\n","  <div id=\"df-66c11c36-f716-433e-9759-5aeaee2b02b8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ru</th>\n","      <th>uk</th>\n","      <th>ka</th>\n","      <th>he</th>\n","      <th>en</th>\n","      <th>de</th>\n","      <th>be</th>\n","      <th>kk</th>\n","      <th>az</th>\n","      <th>hy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9901</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9902</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9903</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9904</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9905</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9906 rows × 10 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66c11c36-f716-433e-9759-5aeaee2b02b8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-66c11c36-f716-433e-9759-5aeaee2b02b8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-66c11c36-f716-433e-9759-5aeaee2b02b8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":[""],"metadata":{"id":"qHmF7AmowoS9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sigmoid = torch.nn.Sigmoid()\n","\n","preds = model(**tokenizer(input, return_tensors='pt')).logits\n","probs = sigmoid(preds)\n","probs = probs.detach()[0]\n","for ind, prob in enumerate(probs):\n","    if prob > 0.5:\n","        print(labels.int2str(ind))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y60O0WQvr78M","executionInfo":{"status":"ok","timestamp":1652181094460,"user_tz":-180,"elapsed":516,"user":{"displayName":"Никита Степанов","userId":"00846477694709899261"}},"outputId":"87898b4f-355b-4cb7-8c05-db7154b8e810"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ru\n","uk\n"]}]}]}