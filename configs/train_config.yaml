model_name: xlm-roberta-base

logging_strategy: epoch
evaluation_strategy: epoch
save_strategy: epoch
save_total_limit: 2

num_train_epochs: 2
learning_rate: 2e-5
weight_decay: 0.01

batch_size: 16